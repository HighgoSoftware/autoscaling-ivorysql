# Autoscaling

Vertical autoscaling for a fleet of postgres instances running in a Kubernetes cluster.

## Overview

We want to dynamically change the amount of CPUs and memory of running postgres instances, _without
breaking TCP connections to postgres_.

This relatively easy when there's already spare resources on the physical (Kubernetes) node, but it
takes careful coordination to move postgres instances from one node to another when the original
node doesn't have the room.

We've [tried a bunch](https://github.com/neondatabase/cloud/issues/1651) of existing tools and
settled on the following:

* Use [VM live migration](https://www.qemu.org/docs/master/devel/migration.html) to move running
  postgres instances between physical nodes
* QEMU is used as our hypervisor
* [NeonVM](https://github.com/neondatabase/neonvm) orchestrates NeonVM VMs as custom resources in
  K8s, and is responsible for scaling allocated resources (CPU and memory _slots_)
* A modified K8s scheduler ensures that we don't overcommit resources and triggers migrations when
  demand is above a pre-configured threshold
* Each VM has a sidecar container in its pod (`autoscaler-agent`) that triggers scaling decisions
  and makes resource requests to the K8s scheduler on its behalf to reserve additional resources.

Networking is preserved across migrations by giving each VM an additional IP address on a bridge
network spanning the cluster with a flat topology; the L2 network figures out "by itself" where to
send the packets after migration.

## Building and running

Build everything:

```sh
vm_image/start-local-registry.sh # required for everything below. Does nothing on repeat
vm_image/build.sh
build/autoscale-scheduler/build.sh
build/autoscaler-agent/build.sh
```

We also require a local build of NeonVM (for now, as of 2022-11-27); which can be done by cloning
the repository, in a different directory:
```sh
git clone -b sharnoff/dev git@github.com:neondatabase/neonvm
cd neonvm  # ^^^^^^^^^^^^ NOTE: needs to be the right branch.

# as root:
CONTROLLER_IMG='localhost:5001/neonvm-controller:latest' \
RUNNER_IMG='localhost:5001/neonvm-runner:latest' \
./build_docker.sh
```

Download various dependencies:

```sh
scripts/download-cni.sh
scripts/download-deployments.sh
```

Set up the cluster:

```sh
scripts/cluster-init.sh
```

Run the VM:

```sh
kubectl apply -f vm-deploy.yaml
```

Run pgbench and watch the vCPU allocation grow:

```sh
scripts/run-bench.sh
# or:
VM_NAME=postgres14-disk-test scripts/run-bench.sh
```

## Architecture

Broadly speaking, the components are:

* `autoscaler-agent`:
  * Gets metrics from VM's `node_exporter` (`http://10.255.255.254:9100/metrics`)
  * Uses `NeonVM` patch requests to resize vCPU and memory
  * Requests vCPU/memory increase, notify decrease to the scheduler plugin (configured port `10299`)
* `scheduler`:
  * Provides the `AutoscaleEnforcer` scheduler plugin, using the `kube-scheduler` plugin interface
  * Handles requests / notifications from `autoscaler-agent`s, limiting them to the node's capacity.
      (Currently reserves some resources for system tasks, via the ConfigMap in `deploy/scheduler-deploy.yaml`.)
* `vm_image`:
  * The normal postgres VM + `node_exporter` image that we've used in other places.
  * **NOTE:** The entire setup requires the registry at `localhost:5001` from `start-local-registry.sh`
* `deploy/neonvm.yaml`:
  * Autogenerated NeonVM deployment from <https://github.com/neondatabase/neonvm>, using Kustomize

Some basics on the `autoscaler-agent` \<-\> `scheduler` protocol:

* All messages are `autoscaler-agent` -> `scheduler`, plus response. The agent sends an
    `AgentRequest` and the scheduler plugin replies with a `PluginResponse`
* All `AgentRequest` contain metrics information and a resource request (may be equal to current)
* When the `autoscaler-agent` wants to *decrease* resource allocation, it does that immediately and
    the `AgentRequest` is informative (i.e., "Hey scheduler, just so you know, I've decreased my
    vCPU. You can allocate that elsewhere").
* When the `autoscaler-agent` wants to *increase* vCPU, it submits the `AgentRequest` and the
    `PluginResponse` contains a `Permit` for resources that may be lower than the requested resource
    amount, but not lower than the current resources (i.e., "Hey scheduler, can I increase to `X`
    vCPUs?" ... "You can only go to `Y`", where `current <= Y <= X`).
  * When there aren't enough resources to satisfy all of the request, the amount unavailable is
      added as "pressure"
* If a node's "pressure" is more than the amount currently being migrated, new pods will selected
    for migration, prioritized based on their reported metrics (lower means more likely).
    * "pressure" is defined as resource allocation above the "watermark" (a value that we try to
        keep usage less than or equal to). Watermarks are set in the `scheduler`'s ConfigMap, in
        `deploy/scheduler-deploy.yaml`.
* The definition of a "compute unit" is defined per-node by the `scheduler`, and all `AgentRequest`s
    must have resources as a multiple of the _last_ compute unit they received from the `scheduler`
    * We say the "last" compute unit, because it can - in theory - be changed at runtime
* The `scheduler` treats resource types independently: it may respond with a `Permit` that is not a
    multiple of the compute units, if there aren't enough resources to fully satisfy the
    `autsocaler-agent`'s request.
    * This approach allows the scheduler to be much simpler, while granting us greater resilience
      and flexibility, and ensuring that resource usage is still _eventually_ balanced according to
      the configured compute unit size.

The files implementing the protocol are in `pkg/agent/run.go` and `pkg/plugin/run.go`, plus API
types in `pkg/api/types.go`.

Currently, the scheduler also appropriately handles pod un-scheduling via `Reserve`/`Unreserve`,
with some initial (but non-binding) capacity checks in the `Filter` step. Pod deletion events are
similarly tracked to release reserved resources.
